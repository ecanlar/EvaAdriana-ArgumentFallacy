{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11499837,"sourceType":"datasetVersion","datasetId":7209398},{"sourceId":11545111,"sourceType":"datasetVersion","datasetId":7240122},{"sourceId":11545559,"sourceType":"datasetVersion","datasetId":7240399}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ff0e233b-18a4-47fc-b17d-74bf82cb86f1","cell_type":"code","source":"!pip install mamkit==0.1.1a2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:44:38.861509Z","iopub.execute_input":"2025-04-24T13:44:38.861757Z","iopub.status.idle":"2025-04-24T13:55:28.314338Z","shell.execute_reply.started":"2025-04-24T13:44:38.861734Z","shell.execute_reply":"2025-04-24T13:55:28.313448Z"}},"outputs":[{"name":"stdout","text":"Collecting mamkit==0.1.1a2\n  Downloading mamkit-0.1.1a2-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.11/dist-packages (from mamkit==0.1.1a2) (1.26.4)\nCollecting resampy==0.4.3 (from mamkit==0.1.1a2)\n  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\nCollecting scikit-image==0.19.2 (from mamkit==0.1.1a2)\n  Downloading scikit-image-0.19.2.tar.gz (22.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting librosa==0.9.1 (from mamkit==0.1.1a2)\n  Downloading librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: nltk~=3.9.1 in /usr/local/lib/python3.11/dist-packages (from mamkit==0.1.1a2) (3.9.1)\nRequirement already satisfied: pandas~=2.2.2 in /usr/local/lib/python3.11/dist-packages (from mamkit==0.1.1a2) (2.2.3)\nRequirement already satisfied: pydub==0.25.1 in /usr/local/lib/python3.11/dist-packages (from mamkit==0.1.1a2) (0.25.1)\nCollecting torch==2.3.0 (from mamkit==0.1.1a2)\n  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting torchaudio==2.3.0 (from mamkit==0.1.1a2)\n  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\nCollecting torchmetrics~=1.4.1 (from mamkit==0.1.1a2)\n  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\nCollecting torchtext==0.18.0 (from mamkit==0.1.1a2)\n  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\nCollecting tqdm~=4.66.5 (from mamkit==0.1.1a2)\n  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting transformers~=4.48.0 (from mamkit==0.1.1a2)\n  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting yt-dlp==2025.2.19 (from mamkit==0.1.1a2)\n  Downloading yt_dlp-2025.2.19-py3-none-any.whl.metadata (171 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Django~=5.1.3 (from mamkit==0.1.1a2)\n  Downloading Django-5.1.8-py3-none-any.whl.metadata (4.1 kB)\nCollecting setuptools~=59.6.0 (from mamkit==0.1.1a2)\n  Downloading setuptools-59.6.0-py3-none-any.whl.metadata (5.0 kB)\nCollecting simplejson==3.20.1 (from mamkit==0.1.1a2)\n  Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from mamkit==0.1.1a2) (0.28.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->mamkit==0.1.1a2) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->mamkit==0.1.1a2) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->mamkit==0.1.1a2) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->mamkit==0.1.1a2) (3.10)\nRequirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (1.15.2)\nRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (1.4.2)\nRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (4.4.2)\nRequirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (0.60.0)\nRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (0.13.1)\nRequirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (1.8.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->mamkit==0.1.1a2) (24.2)\nRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.2->mamkit==0.1.1a2) (3.4.2)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.2->mamkit==0.1.1a2) (11.1.0)\nRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.2->mamkit==0.1.1a2) (2.37.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.2->mamkit==0.1.1a2) (2025.1.10)\nRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.2->mamkit==0.1.1a2) (1.8.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->mamkit==0.1.1a2) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->mamkit==0.1.1a2) (4.13.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->mamkit==0.1.1a2) (1.13.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->mamkit==0.1.1a2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->mamkit==0.1.1a2) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.0 (from torch==2.3.0->mamkit==0.1.1a2)\n  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0->mamkit==0.1.1a2) (2.32.3)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.28.1->mamkit==0.1.1a2) (0.14.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->mamkit==0.1.1a2) (12.8.93)\nCollecting asgiref<4,>=3.8.1 (from Django~=5.1.3->mamkit==0.1.1a2)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from Django~=5.1.3->mamkit==0.1.1a2) (0.5.3)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk~=3.9.1->mamkit==0.1.1a2) (8.1.8)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk~=3.9.1->mamkit==0.1.1a2) (2024.11.6)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy~=1.26.4->mamkit==0.1.1a2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy~=1.26.4->mamkit==0.1.1a2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy~=1.26.4->mamkit==0.1.1a2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy~=1.26.4->mamkit==0.1.1a2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy~=1.26.4->mamkit==0.1.1a2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy~=1.26.4->mamkit==0.1.1a2) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.2.2->mamkit==0.1.1a2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.2.2->mamkit==0.1.1a2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.2.2->mamkit==0.1.1a2) (2025.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics~=1.4.1->mamkit==0.1.1a2) (0.14.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.0->mamkit==0.1.1a2) (0.30.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.0->mamkit==0.1.1a2) (6.0.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.0->mamkit==0.1.1a2) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.0->mamkit==0.1.1a2) (0.5.2)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.45.1->librosa==0.9.1->mamkit==0.1.1a2) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.9.1->mamkit==0.1.1a2) (4.3.7)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas~=2.2.2->mamkit==0.1.1a2) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0->mamkit==0.1.1a2) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0->mamkit==0.1.1a2) (2.3.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1->mamkit==0.1.1a2) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.2->librosa==0.9.1->mamkit==0.1.1a2) (1.17.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx==0.28.1->mamkit==0.1.1a2) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0->mamkit==0.1.1a2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.26.4->mamkit==0.1.1a2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.26.4->mamkit==0.1.1a2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy~=1.26.4->mamkit==0.1.1a2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy~=1.26.4->mamkit==0.1.1a2) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0->mamkit==0.1.1a2) (1.3.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1->mamkit==0.1.1a2) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy~=1.26.4->mamkit==0.1.1a2) (2024.2.0)\nDownloading mamkit-0.1.1a2-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading librosa-0.9.1-py3-none-any.whl (213 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading yt_dlp-2025.2.19-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Django-5.1.8-py3-none-any.whl (8.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading setuptools-59.6.0-py3-none-any.whl (952 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.6/952.6 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nBuilding wheels for collected packages: scikit-image\n  Building wheel for scikit-image (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for scikit-image: filename=scikit_image-0.19.2-cp311-cp311-linux_x86_64.whl size=33912240 sha256=761e4de5fb2aef371456d471e24d8500e2e39f0a70971f956e03ec7e5b603c48\n  Stored in directory: /root/.cache/pip/wheels/eb/f7/41/fbe485a34fb8686331d680bd3ce5b25bee5423e1de8f0ee684\nSuccessfully built scikit-image\nInstalling collected packages: yt-dlp, triton, tqdm, simplejson, setuptools, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, asgiref, nvidia-cusolver-cu12, nvidia-cudnn-cu12, Django, torch, torchaudio, resampy, transformers, torchtext, torchmetrics, scikit-image, librosa, mamkit\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.67.1\n    Uninstalling tqdm-4.67.1:\n      Successfully uninstalled tqdm-4.67.1\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 75.1.0\n    Uninstalling setuptools-75.1.0:\n      Successfully uninstalled setuptools-75.1.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu124\n    Uninstalling torch-2.5.1+cu124:\n      Successfully uninstalled torch-2.5.1+cu124\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.5.1+cu124\n    Uninstalling torchaudio-2.5.1+cu124:\n      Successfully uninstalled torchaudio-2.5.1+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.7.1\n    Uninstalling torchmetrics-1.7.1:\n      Successfully uninstalled torchmetrics-1.7.1\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.25.1\n    Uninstalling scikit-image-0.25.1:\n      Successfully uninstalled scikit-image-0.25.1\n  Attempting uninstall: librosa\n    Found existing installation: librosa 0.10.2.post1\n    Uninstalling librosa-0.10.2.post1:\n      Successfully uninstalled librosa-0.10.2.post1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nsetuptools-scm 8.2.0 requires setuptools>=61, but you have setuptools 59.6.0 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\narviz 0.20.0 requires setuptools>=60.0.0, but you have setuptools 59.6.0 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Django-5.1.8 asgiref-3.8.1 librosa-0.9.1 mamkit-0.1.1a2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 resampy-0.4.3 scikit-image-0.19.2 setuptools-59.6.0 simplejson-3.20.1 torch-2.3.0 torchaudio-2.3.0 torchmetrics-1.4.3 torchtext-0.18.0 tqdm-4.66.6 transformers-4.48.3 triton-2.3.0 yt-dlp-2025.2.19\n","output_type":"stream"}],"execution_count":1},{"id":"713123e1","cell_type":"code","source":"import torch as th\nfrom mamkit.models.audio import TransformerEncoder  # Asegurate que este sea el path correcto\nfrom mamkit.configs.audio import TransformerEncoderConfig\nfrom mamkit.configs.base import ConfigKey\nfrom mamkit.data.datasets import InputMode\n\n# Definir la clave de configuración\nconfig_key = ConfigKey(\n    dataset='mmused-fallacy',\n    task_name='afc',\n    input_mode=InputMode.AUDIO_ONLY,\n    tags={'anonymous'}\n)\n\n# Cargar la configuración usando el mapeo que ya está definido en BiLSTMMFCCsConfig\nconfig = TransformerEncoderConfig.from_config(key=config_key)\n\n# Crear el modelo\nmodel = TransformerEncoder(\n    embedding_dim=config.embedding_dim,\n    encoder=config.encoder,  # ✅ este debe ser un callable como `lambda: MyEncoder()`\n    head=config.head,        # ✅ también callable\n    dropout_rate=config.dropout_rate\n)\n\n# Mover a GPU si está disponible\ndevice = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:28.316215Z","iopub.execute_input":"2025-04-24T13:55:28.316507Z","iopub.status.idle":"2025-04-24T13:55:33.545710Z","shell.execute_reply.started":"2025-04-24T13:55:28.316480Z","shell.execute_reply":"2025-04-24T13:55:33.545134Z"}},"outputs":[],"execution_count":2},{"id":"0b1b340a","cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/audioo/train_afc_audio.csv\")\n\n\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:33.546349Z","iopub.execute_input":"2025-04-24T13:55:33.546703Z","iopub.status.idle":"2025-04-24T13:55:33.603330Z","shell.execute_reply.started":"2025-04-24T13:55:33.546685Z","shell.execute_reply":"2025-04-24T13:55:33.602810Z"}},"outputs":[{"name":"stdout","text":"                                                Ruta  Etiqueta\n0  [WindowsPath('C:/Users/Usuario/MMUSED-fallacy/...         0\n1  [WindowsPath('C:/Users/Usuario/MMUSED-fallacy/...         0\n2  [WindowsPath('C:/Users/Usuario/MMUSED-fallacy/...         1\n3  [WindowsPath('C:/Users/Usuario/MMUSED-fallacy/...         0\n4  [WindowsPath('C:/Users/Usuario/MMUSED-fallacy/...         0\n","output_type":"stream"}],"execution_count":3},{"id":"06046583-c11d-41ae-bd50-619519633aa3","cell_type":"code","source":"# Define el nuevo prefijo\nimport re\nnew_prefix = \"/kaggle/input/datosss/MMUSED-fallacy\"\n\n# Función para limpiar y reemplazar rutas\ndef fix_path(path_str):\n    # Extrae la ruta original desde el WindowsPath(...)\n    matches = re.findall(r\"WindowsPath\\(['\\\"](.*?)['\\\"]\\)\", path_str)\n    if matches:\n        # Reemplaza la parte de la ruta con el nuevo prefijo\n        rel_path = matches[0].split(\"MMUSED-fallacy\")[-1]  # solo lo que viene después de MMUSED-fallacy\n        return new_prefix + rel_path.replace(\"\\\\\", \"/\")   # Normaliza por si acaso\n    return None  # Si no hay match\n\n# Aplica la función a la columna Ruta\ntrain_df[\"Ruta\"] = train_df[\"Ruta\"].apply(fix_path)\n\n# Verifica resultado\nprint(train_df[\"Ruta\"].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:33.604003Z","iopub.execute_input":"2025-04-24T13:55:33.604239Z","iopub.status.idle":"2025-04-24T13:55:33.615193Z","shell.execute_reply.started":"2025-04-24T13:55:33.604214Z","shell.execute_reply":"2025-04-24T13:55:33.614627Z"}},"outputs":[{"name":"stdout","text":"0    /kaggle/input/datosss/MMUSED-fallacy/audio_cli...\n1    /kaggle/input/datosss/MMUSED-fallacy/audio_cli...\n2    /kaggle/input/datosss/MMUSED-fallacy/audio_cli...\n3    /kaggle/input/datosss/MMUSED-fallacy/audio_cli...\n4    /kaggle/input/datosss/MMUSED-fallacy/audio_cli...\nName: Ruta, dtype: object\n","output_type":"stream"}],"execution_count":4},{"id":"cd0841b4-2317-4a01-b833-3df42289280e","cell_type":"code","source":"def parse_paths_from_string(path_str):\n    \"\"\"\n    Dado un string con la ruta, devuelve una lista con la ruta.\n    Si ya es una lista, la devuelve directamente.\n    \"\"\"\n    # Si es una cadena, la envolvemos en una lista\n    if isinstance(path_str, str):\n        return [path_str]\n    # Si ya es una lista, la devolvemos tal cual\n    elif isinstance(path_str, list):\n        return [str(p) for p in path_str]\n    else:\n        print(f\"[ERROR] Tipo no soportado para la ruta: {type(path_str)}\")\n        return []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:33.615792Z","iopub.execute_input":"2025-04-24T13:55:33.616443Z","iopub.status.idle":"2025-04-24T13:55:33.628252Z","shell.execute_reply.started":"2025-04-24T13:55:33.616418Z","shell.execute_reply":"2025-04-24T13:55:33.627743Z"}},"outputs":[],"execution_count":5},{"id":"30100e54-f045-497f-89d1-f664c5a10f6e","cell_type":"code","source":"from torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:33.628975Z","iopub.execute_input":"2025-04-24T13:55:33.629177Z","iopub.status.idle":"2025-04-24T13:55:33.646363Z","shell.execute_reply.started":"2025-04-24T13:55:33.629155Z","shell.execute_reply":"2025-04-24T13:55:33.645750Z"}},"outputs":[],"execution_count":6},{"id":"e37862ae","cell_type":"code","source":"class AudioDataset(Dataset):\n    def __init__(self, dataframe, mfcc_transform):\n        self.df = dataframe\n        self.transform = mfcc_transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        path_str = self.df.iloc[idx]['Ruta']\n    \n        try:\n            # Extraer rutas desde el string\n            paths = parse_paths_from_string(path_str)\n    \n            if not paths:\n                return None\n    \n            waveforms = []\n            for path in paths:\n                waveform, sample_rate = torchaudio.load(path)\n                waveforms.append(waveform)\n    \n            waveform = torch.mean(torch.stack(waveforms), dim=0)\n            mfcc = self.transform(waveform)\n            mfcc = mfcc.squeeze(0).transpose(0, 1)\n    \n            label = self.df.iloc[idx]['Etiqueta']\n    \n            return {\n                'inputs': mfcc,\n                'label': torch.tensor(label, dtype=torch.long)\n            }\n    \n        except Exception as e:\n            print(f\"[ERROR] idx {idx}: {e}\")\n            return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:33.648416Z","iopub.execute_input":"2025-04-24T13:55:33.648650Z","iopub.status.idle":"2025-04-24T13:55:33.660428Z","shell.execute_reply.started":"2025-04-24T13:55:33.648635Z","shell.execute_reply":"2025-04-24T13:55:33.659841Z"}},"outputs":[],"execution_count":7},{"id":"e60a5fcb","cell_type":"code","source":"import torchaudio.transforms as T\n\nmfcc_transform = T.MFCC(\n    sample_rate=16000,\n    n_mfcc=768,  # ⚠️ poco habitual y probablemente no útil\n    melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 768}\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:33.661065Z","iopub.execute_input":"2025-04-24T13:55:33.661774Z","iopub.status.idle":"2025-04-24T13:55:34.328345Z","shell.execute_reply.started":"2025-04-24T13:55:33.661751Z","shell.execute_reply":"2025-04-24T13:55:34.327689Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (768) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"id":"d614b7d3","cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = AudioDataset(train_df, mfcc_transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:34.329061Z","iopub.execute_input":"2025-04-24T13:55:34.329314Z","iopub.status.idle":"2025-04-24T13:55:34.332954Z","shell.execute_reply.started":"2025-04-24T13:55:34.329287Z","shell.execute_reply":"2025-04-24T13:55:34.332099Z"}},"outputs":[],"execution_count":9},{"id":"df200220-f161-496a-ad07-552515f5f151","cell_type":"code","source":"train_dataset[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:34.333812Z","iopub.execute_input":"2025-04-24T13:55:34.334444Z","iopub.status.idle":"2025-04-24T13:55:34.347554Z","shell.execute_reply.started":"2025-04-24T13:55:34.334420Z","shell.execute_reply":"2025-04-24T13:55:34.346897Z"}},"outputs":[{"name":"stdout","text":"[ERROR] idx 1: name 'torchaudio' is not defined\n","output_type":"stream"}],"execution_count":10},{"id":"e0af16c6","cell_type":"code","source":"len(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:34.348294Z","iopub.execute_input":"2025-04-24T13:55:34.348494Z","iopub.status.idle":"2025-04-24T13:55:34.362106Z","shell.execute_reply.started":"2025-04-24T13:55:34.348473Z","shell.execute_reply":"2025-04-24T13:55:34.361469Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"1228"},"metadata":{}}],"execution_count":11},{"id":"5a9ba0c5","cell_type":"code","source":"def collate_fn_pad(batch):\n    import torch\n    import torch.nn.functional as F\n\n\n    # Filtrar elementos inválidos y asegurar que sean tensores 2D\n    batch = [x for x in batch if x is not None and isinstance(x['inputs'], torch.Tensor) and x['inputs'].ndim == 2]\n\n    if len(batch) == 0:\n        print(\"[SKIP] Batch vacío tras filtrar entradas inválidas.\")\n        return None\n\n    inputs = []\n    labels = []\n    lengths = []\n\n    for item in batch:\n        x = item['inputs']\n        y = item['label']\n        inputs.append(x)\n        labels.append(y)\n        lengths.append(x.shape[0])  # secuencia temporal\n\n    # Padding en la dimensión 0 (timesteps)\n    max_len = max(lengths)\n    feature_dim = inputs[0].shape[1]\n\n    padded_inputs = [\n        F.pad(input, (0, 0, 0, max_len - input.shape[0]))  # pad solo en la dimensión de tiempo\n        for input in inputs\n    ]\n\n    try:\n        inputs_tensor = torch.stack(padded_inputs)  # (batch_size, max_len, feature_dim)\n        labels_tensor = torch.tensor(labels)\n\n        # Máscara binaria (1 para datos reales, 0 para padding)\n        input_mask = torch.zeros((len(batch), max_len), dtype=torch.float32)\n        for i, l in enumerate(lengths):\n            input_mask[i, :l] = 1\n\n        return {\n            'inputs': inputs_tensor,\n            'input_mask': input_mask,\n            'label': labels_tensor\n        }\n\n    except Exception as e:\n        print(\"Error al hacer el stack:\", e)\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:34.362773Z","iopub.execute_input":"2025-04-24T13:55:34.363000Z","iopub.status.idle":"2025-04-24T13:55:34.375935Z","shell.execute_reply.started":"2025-04-24T13:55:34.362985Z","shell.execute_reply":"2025-04-24T13:55:34.375295Z"}},"outputs":[],"execution_count":12},{"id":"4806e4df","cell_type":"code","source":"from torch.utils.data import random_split\n\n# Supongamos que tienes el dataset original como `train_dataset`\ntrain_size = int(0.8 * len(train_dataset))  # 80% para entrenamiento\nval_size = len(train_dataset) - train_size  # 20% para validación\n\n# Dividimos el dataset\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\nprint(f\"Train dataset size: {len(train_dataset)}\")\nprint(f\"Validation dataset size: {len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:34.376579Z","iopub.execute_input":"2025-04-24T13:55:34.376783Z","iopub.status.idle":"2025-04-24T13:55:34.392730Z","shell.execute_reply.started":"2025-04-24T13:55:34.376768Z","shell.execute_reply":"2025-04-24T13:55:34.392172Z"}},"outputs":[{"name":"stdout","text":"Train dataset size: 982\nValidation dataset size: 246\n","output_type":"stream"}],"execution_count":13},{"id":"d82e35d2-c9b8-4d62-bee3-83df1e0f4776","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5221):\n        super(PositionalEncoding, self).__init__()\n\n        # Creamos una matriz de posiciones (max_len x d_model)\n        self.d_model = d_model\n        self.max_len = max_len\n\n        # La codificación posicional se genera con senos y cosenos\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))  # (d_model/2)\n\n        # Aplicamos senos y cosenos en las posiciones\n        pe[:, 0::2] = torch.sin(position * div_term)  # las posiciones 0, 2, 4, ...\n        pe[:, 1::2] = torch.cos(position * div_term)  # las posiciones 1, 3, 5, ...\n\n        # Añadimos una dimensión adicional para la compatibilidad con el modelo\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        \"\"\"\n        x: Tensor de entrada de forma (batch_size, seq_len, d_model)\n        \"\"\"\n        seq_len = x.size(1)\n        # Aseguramos que la longitud de la secuencia no supere la longitud máxima\n        pe = self.pe[:, :seq_len]\n        return x + pe\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:34.393406Z","iopub.execute_input":"2025-04-24T13:55:34.393661Z","iopub.status.idle":"2025-04-24T13:55:34.408690Z","shell.execute_reply.started":"2025-04-24T13:55:34.393645Z","shell.execute_reply":"2025-04-24T13:55:34.408140Z"}},"outputs":[],"execution_count":14},{"id":"74142101","cell_type":"code","source":"import torch as th\nimport torchaudio\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm  # Importar tqdm para la barra de progreso\nfrom sklearn.metrics import accuracy_score, f1_score  # Para calcular métricas\n\n# Asegúrate de que el modelo esté en modo de evaluación\n# No lo pongas en eval hasta la parte de validación\n\n# Instanciar la codificación posicional\nd_model = 768  # Este debe ser el tamaño de las representaciones de entrada del modelo\npos_encoder = PositionalEncoding(d_model=d_model, max_len=5000).to(device)   # Usamos 5000 como un valor máximo para max_len\n\n# Crear un DataLoader para iterar sobre el dataset de entrenamiento y validación\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn_pad)\nval_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn_pad)\n\n# Definir un optimizador y una función de pérdida\noptimizer = th.optim.Adam(model.parameters(), lr=0.001)  # Optimización\ncriterion = th.nn.CrossEntropyLoss()  # Función de pérdida para clasificación multiclase\n\n# Medir el tiempo de cada época\nfor epoch in range(5):\n    \n    # Inicializar las listas para las predicciones de esta época\n    train_predictions = []\n    train_true_labels = []\n    val_predictions = []\n    val_true_labels = []\n    \n    # ----- Entrenamiento -----\n    model.train()\n    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\", leave=True)\n    for batch in train_loader_tqdm:\n        if batch is None:\n            continue\n\n        inputs = batch['inputs'].to(device)\n        input_mask = batch['input_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        # Aplicar codificación posicional a las entradas\n        inputs = inputs[:, :5000, :]  # Recortar para que la longitud de la secuencia no supere max_len\n        input_mask = input_mask[:, :5000]  # Recortar la máscara para que coincida con max_len\n        inputs = pos_encoder(inputs)  # Agregar la codificación posicional\n\n        outputs = model({'inputs': inputs, 'input_mask': input_mask})\n\n        # Obtener la pérdida\n        loss = criterion(outputs, labels)\n\n        # Backpropagation y optimización\n        optimizer.zero_grad()  # Resetear los gradientes\n        loss.backward()  # Calcular los gradientes\n        optimizer.step()  # Actualizar los pesos del modelo\n\n        # Obtener las predicciones (puedes aplicar softmax si deseas probabilidades)\n        _, preds = th.max(outputs, 1)  # Si la salida del modelo es logits\n\n        # Almacenar las predicciones y las etiquetas reales\n        train_predictions.extend(preds.cpu().numpy())\n        train_true_labels.extend(labels.cpu().numpy())\n        \n        # Actualizar la barra de progreso de entrenamiento\n        train_loader_tqdm.set_postfix({'train_batch': len(train_predictions)})\n\n    # ----- Validación -----\n    model.eval()\n    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch+1} - Validation\", leave=True)\n    with th.no_grad():  # No calculamos gradientes para la inferencia\n        for batch in val_loader_tqdm:\n            if batch is None:\n                continue\n            inputs = batch['inputs'].to(device)\n            input_mask = batch['input_mask'].to(device)\n            labels = batch['label'].to(device)\n    \n            # Recortar las secuencias y la máscara para que no superen max_len\n            inputs = inputs[:, :5000, :]  # Recortar para que la longitud de la secuencia no supere max_len\n            input_mask = input_mask[:, :5000]  # Recortar la máscara para que coincida con max_len\n    \n            # Aplicar codificación posicional a las entradas\n            inputs = pos_encoder(inputs)  # Agregar la codificación posicional\n    \n            outputs = model({'inputs': inputs, 'input_mask': input_mask})\n    \n            # Obtener las predicciones (puedes aplicar softmax si deseas probabilidades)\n            _, preds = th.max(outputs, 1)  # Si la salida del modelo es logits\n    \n            # Almacenar las predicciones y las etiquetas reales\n            val_predictions.extend(preds.cpu().numpy())\n            val_true_labels.extend(labels.cpu().numpy())\n            \n            # Actualizar la barra de progreso de validación\n            val_loader_tqdm.set_postfix({'val_batch': len(val_predictions)})\n\n    # Calcular y mostrar las métricas después de cada época\n    accuracy = accuracy_score(val_true_labels, val_predictions)\n    f1 = f1_score(val_true_labels, val_predictions, average='weighted')\n    macro_f1 = f1_score(val_true_labels, val_predictions, average='macro')\n\n    print(f\"Epoch {epoch+1} completed\")\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(f\"Validation F1: {f1:.4f}\")\n    print(f\"Validation Macro F1: {macro_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:55:34.409608Z","iopub.execute_input":"2025-04-24T13:55:34.409817Z","iopub.status.idle":"2025-04-24T13:59:10.081873Z","shell.execute_reply.started":"2025-04-24T13:55:34.409803Z","shell.execute_reply":"2025-04-24T13:59:10.081161Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 - Training: 100%|██████████| 491/491 [00:44<00:00, 11.12it/s, train_batch=982]\nEpoch 1 - Validation: 100%|██████████| 123/123 [00:08<00:00, 14.01it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 completed\nValidation Accuracy: 0.6626\nValidation F1: 0.5281\nValidation Macro F1: 0.1328\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.50it/s, train_batch=982]\nEpoch 2 - Validation: 100%|██████████| 123/123 [00:06<00:00, 18.89it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 completed\nValidation Accuracy: 0.6626\nValidation F1: 0.5281\nValidation Macro F1: 0.1328\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.71it/s, train_batch=982]\nEpoch 3 - Validation: 100%|██████████| 123/123 [00:06<00:00, 19.14it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 completed\nValidation Accuracy: 0.6626\nValidation F1: 0.5281\nValidation Macro F1: 0.1328\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.68it/s, train_batch=982]\nEpoch 4 - Validation: 100%|██████████| 123/123 [00:06<00:00, 19.66it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 completed\nValidation Accuracy: 0.6626\nValidation F1: 0.5281\nValidation Macro F1: 0.1328\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.65it/s, train_batch=982]\nEpoch 5 - Validation: 100%|██████████| 123/123 [00:06<00:00, 18.91it/s, val_batch=246]","output_type":"stream"},{"name":"stdout","text":"Epoch 5 completed\nValidation Accuracy: 0.6545\nValidation F1: 0.5268\nValidation Macro F1: 0.1325\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"id":"f2c41fc9-6bed-4315-8798-d195f158c9fe","cell_type":"code","source":"# Medir el tiempo de cada época\nfor epoch in range(5):\n    \n    # Inicializar las listas para las predicciones de esta época\n    train_predictions = []\n    train_true_labels = []\n    val_predictions = []\n    val_true_labels = []\n    \n    # ----- Entrenamiento -----\n    model.train()\n    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\", leave=True)\n    for batch in train_loader_tqdm:\n        if batch is None:\n            continue\n\n        inputs = batch['inputs'].to(device)\n        input_mask = batch['input_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        # Aplicar codificación posicional a las entradas\n        inputs = inputs[:, :5000, :]  # Recortar para que la longitud de la secuencia no supere max_len\n        input_mask = input_mask[:, :5000]  # Recortar la máscara para que coincida con max_len\n        inputs = pos_encoder(inputs)  # Agregar la codificación posicional\n\n        outputs = model({'inputs': inputs, 'input_mask': input_mask})\n\n        # Obtener la pérdida\n        loss = criterion(outputs, labels)\n\n        # Backpropagation y optimización\n        optimizer.zero_grad()  # Resetear los gradientes\n        loss.backward()  # Calcular los gradientes\n        optimizer.step()  # Actualizar los pesos del modelo\n\n        # Obtener las predicciones (puedes aplicar softmax si deseas probabilidades)\n        _, preds = th.max(outputs, 1)  # Si la salida del modelo es logits\n\n        # Almacenar las predicciones y las etiquetas reales\n        train_predictions.extend(preds.cpu().numpy())\n        train_true_labels.extend(labels.cpu().numpy())\n        \n        # Actualizar la barra de progreso de entrenamiento\n        train_loader_tqdm.set_postfix({'train_batch': len(train_predictions)})\n\n    # ----- Validación -----\n    model.eval()\n    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch+1} - Validation\", leave=True)\n    with th.no_grad():  # No calculamos gradientes para la inferencia\n        for batch in val_loader_tqdm:\n            if batch is None:\n                continue\n            inputs = batch['inputs'].to(device)\n            input_mask = batch['input_mask'].to(device)\n            labels = batch['label'].to(device)\n    \n            # Recortar las secuencias y la máscara para que no superen max_len\n            inputs = inputs[:, :5000, :]  # Recortar para que la longitud de la secuencia no supere max_len\n            input_mask = input_mask[:, :5000]  # Recortar la máscara para que coincida con max_len\n    \n            # Aplicar codificación posicional a las entradas\n            inputs = pos_encoder(inputs)  # Agregar la codificación posicional\n    \n            outputs = model({'inputs': inputs, 'input_mask': input_mask})\n    \n            # Obtener las predicciones (puedes aplicar softmax si deseas probabilidades)\n            _, preds = th.max(outputs, 1)  # Si la salida del modelo es logits\n    \n            # Almacenar las predicciones y las etiquetas reales\n            val_predictions.extend(preds.cpu().numpy())\n            val_true_labels.extend(labels.cpu().numpy())\n            \n            # Actualizar la barra de progreso de validación\n            val_loader_tqdm.set_postfix({'val_batch': len(val_predictions)})\n\n    # Calcular y mostrar las métricas después de cada época\n    accuracy = accuracy_score(val_true_labels, val_predictions)\n    f1 = f1_score(val_true_labels, val_predictions, average='weighted')\n    macro_f1 = f1_score(val_true_labels, val_predictions, average='macro')\n\n    print(f\"Epoch {epoch+1} completed\")\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(f\"Validation F1: {f1:.4f}\")\n    print(f\"Validation Macro F1: {macro_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:59:10.085735Z","iopub.execute_input":"2025-04-24T13:59:10.085946Z","iopub.status.idle":"2025-04-24T14:02:30.401695Z","shell.execute_reply.started":"2025-04-24T13:59:10.085931Z","shell.execute_reply":"2025-04-24T14:02:30.400929Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.65it/s, train_batch=982]\nEpoch 1 - Validation: 100%|██████████| 123/123 [00:06<00:00, 18.20it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 completed\nValidation Accuracy: 0.6382\nValidation F1: 0.5551\nValidation Macro F1: 0.1899\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.65it/s, train_batch=982]\nEpoch 2 - Validation: 100%|██████████| 123/123 [00:06<00:00, 19.39it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 completed\nValidation Accuracy: 0.6626\nValidation F1: 0.5351\nValidation Macro F1: 0.1434\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.78it/s, train_batch=982]\nEpoch 3 - Validation: 100%|██████████| 123/123 [00:06<00:00, 19.40it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 completed\nValidation Accuracy: 0.6667\nValidation F1: 0.5536\nValidation Macro F1: 0.1697\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.55it/s, train_batch=982]\nEpoch 4 - Validation: 100%|██████████| 123/123 [00:06<00:00, 19.36it/s, val_batch=246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 completed\nValidation Accuracy: 0.6463\nValidation F1: 0.5480\nValidation Macro F1: 0.1713\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - Training: 100%|██████████| 491/491 [00:33<00:00, 14.72it/s, train_batch=982]\nEpoch 5 - Validation: 100%|██████████| 123/123 [00:07<00:00, 17.32it/s, val_batch=246]","output_type":"stream"},{"name":"stdout","text":"Epoch 5 completed\nValidation Accuracy: 0.6301\nValidation F1: 0.5473\nValidation Macro F1: 0.1824\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"id":"0d0dad4e","cell_type":"code","source":"# Imprimir las primeras predicciones\nprint(val_predictions[:20])\nprint(val_true_labels[:20])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:02:36.789648Z","iopub.execute_input":"2025-04-24T14:02:36.789930Z","iopub.status.idle":"2025-04-24T14:02:36.794219Z","shell.execute_reply.started":"2025-04-24T14:02:36.789912Z","shell.execute_reply":"2025-04-24T14:02:36.793554Z"}},"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0]\n[0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 3, 0, 2, 0, 0]\n","output_type":"stream"}],"execution_count":17},{"id":"175fe45d","cell_type":"code","source":"class AudioTestDataset(Dataset):\n    def __init__(self, dataframe, mfcc_transform):\n        self.df = dataframe\n        self.transform = mfcc_transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        path_str = self.df.iloc[idx]['Ruta']\n    \n        try:\n            # Extraer rutas desde el string\n            paths = parse_paths_from_string(path_str)\n    \n            if not paths:\n                return None\n    \n            waveforms = []\n            for path in paths:\n                waveform, sample_rate = torchaudio.load(path)\n                waveforms.append(waveform)\n    \n            waveform = torch.mean(torch.stack(waveforms), dim=0)\n            mfcc = self.transform(waveform)\n            mfcc = mfcc.squeeze(0).transpose(0, 1)\n    \n            return {\n                'inputs': mfcc\n            }\n    \n        except Exception as e:\n            print(f\"[ERROR] idx {idx}: {e}\")\n            return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:02:42.406990Z","iopub.execute_input":"2025-04-24T14:02:42.407541Z","iopub.status.idle":"2025-04-24T14:02:42.413721Z","shell.execute_reply.started":"2025-04-24T14:02:42.407516Z","shell.execute_reply":"2025-04-24T14:02:42.412817Z"}},"outputs":[],"execution_count":18},{"id":"7d575d76","cell_type":"code","source":"def collate_fn_pad_test(batch):\n    import torch\n    import torch.nn.functional as F\n\n\n    # Filtrar elementos inválidos y asegurar que sean tensores 2D\n    batch = [x for x in batch if x is not None and isinstance(x['inputs'], torch.Tensor) and x['inputs'].ndim == 2]\n\n    if len(batch) == 0:\n        print(\"[SKIP] Batch vacío tras filtrar entradas inválidas.\")\n        return None\n\n    inputs = []\n    lengths = []\n\n    for item in batch:\n        x = item['inputs']\n        inputs.append(x)\n        lengths.append(x.shape[0])  # secuencia temporal\n\n    # Padding en la dimensión 0 (timesteps)\n    max_len = max(lengths)\n    feature_dim = inputs[0].shape[1]\n\n    padded_inputs = [\n        F.pad(input, (0, 0, 0, max_len - input.shape[0]))  # pad solo en la dimensión de tiempo\n        for input in inputs\n    ]\n\n    try:\n        inputs_tensor = torch.stack(padded_inputs)  # (batch_size, max_len, feature_dim)\n\n        # Máscara binaria (1 para datos reales, 0 para padding)\n        input_mask = torch.zeros((len(batch), max_len), dtype=torch.float32)\n        for i, l in enumerate(lengths):\n            input_mask[i, :l] = 1\n\n        return {\n            'inputs': inputs_tensor,\n            'input_mask': input_mask,\n        }\n\n    except Exception as e:\n        print(\"Error al hacer el stack:\", e)\n        return None\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:02:42.776068Z","iopub.execute_input":"2025-04-24T14:02:42.776608Z","iopub.status.idle":"2025-04-24T14:02:42.782952Z","shell.execute_reply.started":"2025-04-24T14:02:42.776582Z","shell.execute_reply":"2025-04-24T14:02:42.782252Z"}},"outputs":[],"execution_count":19},{"id":"5348767c","cell_type":"code","source":"# Crear el dataset para test (usando la misma transformación)\n\n\n\ntest_df = pd.read_csv(\"/kaggle/input/audioo/train_afc_audio.csv\")\ntest_df[\"Ruta\"] = test_df[\"Ruta\"].apply(fix_path)\ntest_dataset = AudioTestDataset(test_df, mfcc_transform)\n\n# Crear el DataLoader para el conjunto de test\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_pad_test)\n\n# Ahora puedes realizar la evaluación sobre el conjunto de test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:02:44.856052Z","iopub.execute_input":"2025-04-24T14:02:44.856381Z","iopub.status.idle":"2025-04-24T14:02:44.873091Z","shell.execute_reply.started":"2025-04-24T14:02:44.856357Z","shell.execute_reply":"2025-04-24T14:02:44.872414Z"}},"outputs":[],"execution_count":20},{"id":"41cf9af2","cell_type":"code","source":"len(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:02:47.481265Z","iopub.execute_input":"2025-04-24T14:02:47.481739Z","iopub.status.idle":"2025-04-24T14:02:47.486978Z","shell.execute_reply.started":"2025-04-24T14:02:47.481715Z","shell.execute_reply":"2025-04-24T14:02:47.486422Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"1228"},"metadata":{}}],"execution_count":21},{"id":"f31f2610","cell_type":"code","source":"import numpy as np\n\nmodel.eval()\ntest_predictions = []\n\n# Usamos tqdm para mostrar el progreso\ntest_loader_tqdm = tqdm(test_loader, desc=\"Test Evaluation\", leave=True)\n\nwith th.no_grad():\n    for batch in test_loader_tqdm:\n        if batch is None or 'inputs' not in batch or len(batch['inputs']) == 0:  # Verifica si el batch está vacío o no tiene 'inputs'\n            test_predictions.append(0)  # Usamos append para agregar un único valor\n\n        else:\n            inputs = batch['inputs'].to(device)\n            input_mask = batch['input_mask'].to(device)\n    \n            # Recortar las secuencias y la máscara para que no superen max_len\n            inputs = inputs[:, :5000, :]  # Recortar para que la longitud de la secuencia no supere max_len\n            input_mask = input_mask[:, :5000]  # Recortar la máscara para que coincida con max_len\n\n            # Aplicar codificación posicional a las entradas\n            inputs = pos_encoder(inputs)  # Agregar la codificación posicional\n    \n            outputs = model({'inputs': inputs, 'input_mask': input_mask})\n            \n            _, preds = torch.max(outputs, 1)\n            test_predictions.extend(preds.cpu().numpy())  # extend para agregar múltiples predicciones\n\n# Reemplazamos los NaN con 0 (o con la clase mayoritaria que prefieras)\ntest_predictions = [0 if np.isnan(pred) else pred for pred in test_predictions]\n\n# Ahora `test_predictions` tiene las predicciones con NaN reemplazados por 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:04:50.282043Z","iopub.execute_input":"2025-04-24T14:04:50.282324Z","iopub.status.idle":"2025-04-24T14:05:20.489526Z","shell.execute_reply.started":"2025-04-24T14:04:50.282302Z","shell.execute_reply":"2025-04-24T14:05:20.488880Z"}},"outputs":[{"name":"stderr","text":"Test Evaluation: 100%|██████████| 1228/1228 [00:30<00:00, 40.67it/s]\n","output_type":"stream"}],"execution_count":24},{"id":"c4c5d4e5","cell_type":"code","source":"# Ahora, puedes guardar las predicciones de test o visualizarlas\nprint(\"Test Predictions:\", test_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:05:23.713246Z","iopub.execute_input":"2025-04-24T14:05:23.713930Z","iopub.status.idle":"2025-04-24T14:05:23.717860Z","shell.execute_reply.started":"2025-04-24T14:05:23.713908Z","shell.execute_reply":"2025-04-24T14:05:23.717069Z"}},"outputs":[{"name":"stdout","text":"Test Predictions: [0, 1, 1, 5, 0, 5, 5, 5, 0, 1, 5, 5, 5, 2, 5, 0, 0, 0, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 1, 1, 0, 1, 1, 1, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 5, 5, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":25},{"id":"84aa88e4","cell_type":"code","source":"len(test_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:05:27.163446Z","iopub.execute_input":"2025-04-24T14:05:27.164275Z","iopub.status.idle":"2025-04-24T14:05:27.168720Z","shell.execute_reply.started":"2025-04-24T14:05:27.164249Z","shell.execute_reply":"2025-04-24T14:05:27.168121Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"1228"},"metadata":{}}],"execution_count":26},{"id":"18a9f709","cell_type":"code","source":"df_predictions = pd.DataFrame(test_predictions, columns=[\"Prediction\"])\n\n# Guardar el DataFrame en un archivo CSV\ndf_predictions.to_csv('/kaggle/working/BILSTM_audio.csv', index=False)\n\nprint(\"Las predicciones han sido guardadas en 'test_predictions.csv'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:05:37.255793Z","iopub.execute_input":"2025-04-24T14:05:37.256367Z","iopub.status.idle":"2025-04-24T14:05:37.268624Z","shell.execute_reply.started":"2025-04-24T14:05:37.256343Z","shell.execute_reply":"2025-04-24T14:05:37.267963Z"}},"outputs":[{"name":"stdout","text":"Las predicciones han sido guardadas en 'test_predictions.csv'.\n","output_type":"stream"}],"execution_count":27},{"id":"5af5875f","cell_type":"code","source":"df_predictions[\"Prediction\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:05:48.337296Z","iopub.execute_input":"2025-04-24T14:05:48.337549Z","iopub.status.idle":"2025-04-24T14:05:48.356502Z","shell.execute_reply.started":"2025-04-24T14:05:48.337531Z","shell.execute_reply":"2025-04-24T14:05:48.355956Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Prediction\n0    1081\n2      93\n1      35\n5      19\nName: count, dtype: int64"},"metadata":{}}],"execution_count":28},{"id":"52f6fc5e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}